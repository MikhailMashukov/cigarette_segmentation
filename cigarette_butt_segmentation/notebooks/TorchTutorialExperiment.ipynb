{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"TorchTutorialExperiment.ipynb","provenance":[{"file_id":"1U6sVtVVeq5Pd7eCq1YKZnUk_VH00CgB7","timestamp":1601675524738}],"collapsed_sections":["fkzslnex56X-","rytHcSeMwPXi","we_ei9xEwPZO"]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"12eTZAm86zk9","outputId":"e01537bc-92a5-4440-8783-f1649b63e8e9","colab":{"base_uri":"https://localhost:8080/","height":464}},"source":["!nvidia-smi\n","\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","work_root = \"/content/gdrive/My Drive/cigarette_butt_segmentation\"\n","%cd \"$work_root\"\n","data_root = '/content/data'\n","if not os.path.exists(data_root):\n","    !unzip data/cig_butts.zip -d $data_root\n","    !mv $data_root/cig_butts/* $data_root\n","    !rm -r $data_root/cig_butts \n","out_dir = work_root + '/results'\n","weights_file_name_templ = out_dir + '/CigHeadWeights_Epoch%d.h5'\n","\n","if 0:       # Warning: one-time operation, then the sources are supposed to be edited\n","    %cd /content\n","    !git clone https://github.com/pytorch/vision.git\n","    %cd vision\n","    !git checkout v0.3.0\n","\n","    target_dir = work_root + \"/lib/detection\"\n","    %mkdir \"$target_dir\"\n","    # # !cp references/detection/utils.py ../\n","    # # !cp references/detection/transforms.py ../\n","    # !cp references/detection/coco_eval.py \"$work_root/lib/torchvision/\"\n","    # !cp references/detection/engine.py \"$work_root/lib/torchvision/\"\n","    # # !cp references/detection/coco_utils.py ../\n","    !cp references/detection/*.py \"$target_dir/\"\n","\n","    %cd $work_root"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Oct  5 13:40:14 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bUnpMSimwPW6"},"source":["import cv2\n","import json\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from PIL import ImageFile\n","from glob import glob\n","\n","from lib import *\n","from lib.net import *\n","from lib.dataset import *\n","\n","# from lib.torchvision.transforms1 import get_transform\n","# from lib.torchvision import train\n","# from lib.torchvision import engine\n","# from lib.torchvision.utils import *\n","\n","# %ls -l lib/detection/\n","import lib.detection.transforms\n","from lib.detection.transforms import get_transform\n","from lib.detection import train\n","from lib.detection.det_utils import *\n","\n","%matplotlib inline\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KA27AA9IU9u0"},"source":["# import torchvision.models.segmentation as segmentation\n","\n","# # model = segmentation.deeplabv3_resnet50(True, True, 2)\n","#     # Fails because it is pretrained on 21 classes\n","\n","# import torchvision\n","# from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n"," \n","# # load a model pre-trained on COCO\n","# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","\n","# # replace the classifier with a new one, that has\n","# # num_classes which is user-defined\n","# num_classes = 2  # 1 class (person) + background\n","# # get number of input features for the classifier\n","# in_features = model.roi_heads.box_predictor.cls_score.in_features\n","# # replace the pre-trained head with a new one\n","# model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oL1OEv2layHM"},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","num_classes = 2\n","model = get_instance_segmentation_model(num_classes, True)\n","model.to(device)\n","# criterion = train.get_criterion()\n","epochNum = 0\n","\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","\n","# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","#                                                step_size=3,\n","#                                                gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISlyQ6xigvdu"},"source":["if 0:\n","    save_model_state(model.roi_heads.mask_predictor, weights_file_name_templ % epochNum)\n","    save_model_state(model, (weights_file_name_templ % epochNum) + '_full')\n","elif 1:\n","    epochNum = 80\n","    load_model_state(model.roi_heads.mask_predictor, weights_file_name_templ % epochNum)\n","    load_model_state(model, (weights_file_name_templ % epochNum) + '_full')  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fyqUrAwiY2Md"},"source":["dataset = CigDataset(data_root + '/train', get_transform(train=True))\n","dataset_test = CigDataset(data_root + '/val', get_transform(train=False))\n","\n","# split the dataset in train and test set\n","torch.manual_seed(1)\n","# indices = torch.randperm(len(dataset)).tolist()\n","# dataset = torch.utils.data.Subset(dataset, range(100))\n","# dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n","\n","# define training and validation data loaders\n","data_loader = torch.utils.data.DataLoader(\n","    dataset, batch_size=8, shuffle=True, num_workers=4,\n","    collate_fn=collate_fn)\n","\n","data_loader_test = torch.utils.data.DataLoader(\n","    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n","    collate_fn=collate_fn)\n","\n","# dataset[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCTCehCqFYO8"},"source":["for i in range(10):\n","    img, target = dataset[i // 3 + 1]\n","    plt.imshow(np.transpose(img, (1, 2, 0)))\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9JDxYzo76Xc"},"source":["# train.evaluate(model, data_loader, device=device, printFunc=printProgress)   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUQ-Cg6e7_ot"},"source":["def engine_get_dice(target, pred, threshold=0.5):\n"," \n","    # print(src_targets)\n","    target_mask_count = target['masks'].shape[0]\n","    if target_mask_count == 0:\n","        return 0\n","    target_mask_sum = target['masks'][0].numpy()\n","    for i in range(1, target_mask_count):\n","        target_mask_sum += target['masks'][i].numpy()\n","    target_mask = (target_mask_sum > 0)\n","\n","    # print(target_mask_sum.shape, np.where(target_mask))\n","    print('engine_get_dice', 'target_mask.sum()', target_mask.sum(), pred['masks'].shape)\n","    pred_mask_count = output['masks'].shape[0]\n","    if pred_mask_count == 0:\n","        return 0\n","        \n","    intersection_sum = 0\n","    im_sum = target_mask.sum()\n","    preds = pred['masks'].numpy() > threshold\n","    for mask_ind in range(pred_mask_count):\n","        pred_mask = preds[mask_ind, 0]\n","        print('pred_mask ', pred_mask.shape)\n","        intersection_sum += (target_mask & pred_mask).sum()\n","        im_sum += pred_mask.sum()\n","    return 2.0 * intersection_sum / (im_sum + 1e-1)\n","        \n","# dices = engine.d\n","# np.mean(dices)\n","# print(type(np.mean(dices)))\n","# printProgress(\"Dices avg %.5f, all: %s\" % (np.mean(dices), str(dices)))\n","# # engine_get_dice(engine.s, engine.p)\n","# # (engine.t[2]['masks'].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3NIzEjXbZE0"},"source":["num_epochs = 100\n","\n","learnRate = 2e-3\n","for epoch in range(num_epochs):\n","    train.evaluate(model, data_loader_test, device=device, printFunc=printProgress)   \n","    for g in optimizer.param_groups:\n","        g['lr'] = learnRate\n","    train.train_one_epoch(model, optimizer, data_loader, device, epochNum, \n","                          print_freq=10, printFunc=printProgress)\n","    # train.train_one_epoch(model, train.criterion, optimizer, data_loader, lr_scheduler, device,\n","    #                       epochNum, print_freq=10)\n","    # lr_scheduler.step()\n","    \n","    epochNum += 1\n","    if epochNum % 15 == 0:\n","        save_model_state(model.roi_heads.mask_predictor, weights_file_name_templ % epochNum)\n","        save_model_state(model, (weights_file_name_templ % epochNum) + '_full') \n","    # train.evaluate(model, data_loader_test, device=device, printFunc=printProgress)    \n","    \n","    if epochNum % 5 == 0:\n","        learnRate /= 5    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fkzslnex56X-"},"source":["# Анализ получившейся сети"]},{"cell_type":"code","metadata":{"id":"wsVNiWKDhx20"},"source":["img_idxs = range(100)  # sorted_dice_inds[:10]\n","rowCount = 1 # len(img_idxs)\n","colCount = 4\n","log_thresholds = [0.1, 0.3, 0.5, 0.7, 0.95]\n","threshold_to_use_ind = 2\n","model.eval()\n","dices = []\n","with torch.no_grad():\n","    for img_idx2, img_idx in enumerate(img_idxs):\n","        img, target = dataset[img_idx]\n","        images = images_to_device(img, device)\n","        targets = targets_to_device(target, device)\n","        pred = model(images)\n","        masks = pred[0]['masks'].cpu()\n","\n","        mask_count = masks.shape[0]\n","        cur_dices = []\n","        for threshold in [0.1, 0.3, 0.5, 0.7, 0.95]:\n","            if mask_count != 0:\n","                dice = get_dice(target['masks'][0].numpy().astype(bool),\n","                                masks[0, 0].numpy() > threshold) / mask_count\n","                    # Некоторая вариация метрики - лишние предсказанные маски кратно понижают оценку\n","            else:\n","                dice = 0\n","            cur_dices.append(dice)\n","        print('Image %d 0.1, 0.3, 0.5, 0.7, 0.95 thresholds dices: %s, masks: %s, %d' % \\\n","              (img_idx, ', '.join([('%.3f' % d) for d in cur_dices]), masks.shape, mask_count))\n","        dices.append(cur_dices[threshold_to_use_ind])\n","        if cur_dices[threshold_to_use_ind] > 0.95:\n","            continue\n","\n","        plt.figure(figsize=(12, 8))        \n","        zero_mask = np.zeros(list(masks.shape[2:]))\n","        mask_sum = np.copy(zero_mask)        \n","        for mask_ind in range(min(colCount - 1, mask_count)):\n","            # mask = masks[mask_ind, 0].mul((mask_ind + 1) * 10).byte().numpy()\n","            mask = masks[mask_ind, 0].numpy()\n","            where = np.where(mask > 0.5)\n","            # where = (where[0] , where[1] + 50)\n","            # mask[where] = 0.3\n","            target_where = np.where(target['masks'][0].numpy() > 0)\n","            # print('where', mask[where][:50])\n","            print('target bbox', target['boxes'])\n","            print('Mask min %.2f, max %.2f, coords (%.1f, %.1f), area %d, target area %d' % \\\n","                  (mask[where].min(), mask.max(), where[1][0], where[0][0], len(where[0]),\n","                   len(target_where[0])))\n","            # mask_sum[where] = mask_sum[where] * 0.7 + 0.3\n","            mask_rgb = np.stack([mask, target['masks'][0], zero_mask], axis=2)\n","            mask_rgb = np.array(mask_rgb * 255, dtype=np.uint8)\n","\n","            bbox = expand_bbox(target['boxes'][0].numpy().astype(int), 15, mask.shape[-1])\n","            ax = plt.subplot(rowCount, colCount, mask_ind + 2)\n","                # For plots matrix - also img_idx2 * colCount + \n","            im = ax.imshow(mask_rgb[bbox[1] : bbox[3], bbox[0] : bbox[2]]) # [100:400, 100:400]) \n","            # plt.colorbar(im, ax=ax)\n","        # print(mask_sum.shape, target['masks'].shape)\n","        # mask_sum = np.stack([mask_sum, target['masks'][0], zero_mask], axis=2) * 255\n","        ax = plt.subplot(rowCount, colCount, 1)\n","        # im = ax.imshow(mask_sum)\n","        im = ax.imshow(np.transpose(img, (1, 2, 0)))\n","\n","        # # Runs the entire evaluator on one image. But the results are non-visual\n","        # one_img_dataset = torch.utils.data.Subset(dataset, [img_idx])\n","        # one_img_data_loader = torch.utils.data.DataLoader(\n","        #         one_img_dataset, batch_size=1, shuffle=False, num_workers=1,\n","        #         collate_fn=collate_fn)\n","        # train.evaluate(model, one_img_data_loader, device=device)\n","        plt.show()\n","\n","dices = np.array(dices)\n","sorted_dice_inds = np.argsort(dices)\n","print('Threshold %f dices: %s' % (log_thresholds[threshold_to_use_ind], dices[sorted_dice_inds]))\n","print('Dices mean: %.5f' % np.mean(dices))\n","# pred\n","# Image.fromarray(pred[0]['masks'][0, 0].mul(255).byte().cpu().numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4iBXUEzkcHy"},"source":["img_idxs = range(200)  # sorted_dice_inds[:10]\n","rowCount = 1 # len(img_idxs)\n","colCount = 4\n","log_thresholds = [0.1, 0.3, 0.5, 0.7, 0.95]\n","threshold_to_use_ind = 2\n","model.eval()\n","dices = []\n","with torch.no_grad():\n","    for img_idx2, img_idx in enumerate(img_idxs):\n","        img, target = dataset_test[img_idx]\n","        images = images_to_device(img, device)\n","        targets = targets_to_device(target, device)\n","        pred = model(images)\n","        masks = pred[0]['masks'].cpu()\n","\n","        mask_count = masks.shape[0]\n","        cur_dices = []\n","        for threshold in [0.1, 0.3, 0.5, 0.7, 0.95]:\n","            if mask_count != 0:\n","                dice = get_dice(target['masks'][0].numpy().astype(bool),\n","                                masks[0, 0].numpy() > threshold) / mask_count\n","                    # Некоторая вариация метрики - лишние предсказанные маски кратно понижают оценку\n","            else:\n","                dice = 0\n","            cur_dices.append(dice)\n","        print('Image %d 0.1, 0.3, 0.5, 0.7, 0.95 thresholds dices: %s, masks: %s, %d' % \\\n","              (img_idx, ', '.join([('%.3f' % d) for d in cur_dices]), masks.shape, mask_count))\n","        dices.append(cur_dices[threshold_to_use_ind])\n","        if cur_dices[threshold_to_use_ind] > 0.95:\n","            continue\n","\n","        plt.figure(figsize=(12, 8))        \n","        zero_mask = np.zeros(list(masks.shape[2:]))\n","        mask_sum = np.copy(zero_mask)        \n","        for mask_ind in range(min(colCount - 1, mask_count)):\n","            # mask = masks[mask_ind, 0].mul((mask_ind + 1) * 10).byte().numpy()\n","            mask = masks[mask_ind, 0].numpy()\n","            where = np.where(mask > 0.5)\n","            # where = (where[0] , where[1] + 50)\n","            # mask[where] = 0.3\n","            target_where = np.where(target['masks'][0].numpy() > 0)\n","            # print('where', mask[where][:50])\n","            print('target bbox', target['boxes'])\n","            print('Mask min %.2f, max %.2f, coords (%.1f, %.1f), area %d, target area %d' % \\\n","                  (mask[where].min(), mask.max(), where[1][0], where[0][0], len(where[0]),\n","                   len(target_where[0])))\n","            # mask_sum[where] = mask_sum[where] * 0.7 + 0.3\n","            mask_rgb = np.stack([mask, target['masks'][0], zero_mask], axis=2)\n","            mask_rgb = np.array(mask_rgb * 255, dtype=np.uint8)\n","\n","            bbox = expand_bbox(target['boxes'][0].numpy().astype(int), 15, mask.shape[-1])\n","            ax = plt.subplot(rowCount, colCount, mask_ind + 2)\n","                # For plots matrix - also img_idx2 * colCount + \n","            im = ax.imshow(mask_rgb[bbox[1] : bbox[3], bbox[0] : bbox[2]]) # [100:400, 100:400]) \n","            # plt.colorbar(im, ax=ax)\n","        # print(mask_sum.shape, target['masks'].shape)\n","        # mask_sum = np.stack([mask_sum, target['masks'][0], zero_mask], axis=2) * 255\n","        ax = plt.subplot(rowCount, colCount, 1)\n","        # im = ax.imshow(mask_sum)\n","        im = ax.imshow(np.transpose(img, (1, 2, 0)))\n","\n","        # # Runs the entire evaluator on one image. But the results are non-visual\n","        # one_img_dataset = torch.utils.data.Subset(dataset, [img_idx])\n","        # one_img_data_loader = torch.utils.data.DataLoader(\n","        #         one_img_dataset, batch_size=1, shuffle=False, num_workers=1,\n","        #         collate_fn=collate_fn)\n","        # train.evaluate(model, one_img_data_loader, device=device)\n","        plt.show()\n","\n","dices = np.array(dices)\n","sorted_dice_inds = np.argsort(dices)\n","print('Threshold %f dices: %s' % (log_thresholds[threshold_to_use_ind], dices[sorted_dice_inds]))\n","print('Dices mean: %.5f' % np.mean(dices))\n","# pred\n","# Image.fromarray(pred[0]['masks'][0, 0].mul(255).byte().cpu().numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rytHcSeMwPXi"},"source":["# Данные, метрики и доступные функции"]},{"cell_type":"markdown","metadata":{"id":"uCeB_dCswPXl"},"source":["Посмотрим на данные:"]},{"cell_type":"code","metadata":{"id":"ZEvZJdDVwPXo"},"source":["def show_images(data_path, img_ids):\n","    images = os.listdir(f\"{data_path}/images\")\n","    annotations = json.load(open(f\"{data_path}/coco_annotations.json\", \"r\"))\n","    for img_id in img_ids:\n","        img = None\n","        for ext in ['png', 'jpg', 'jpeg', 'gif']:\n","            img_path = f\"{data_path}/images/{img_id:08}.{ext}\"\n","            if os.path.exists(img_path):\n","                img = np.array(Image.open(img_path))\n","        mask = utils.get_mask(img_id, annotations)  # [130:170, 270:350]\n","        show.show_img_with_mask(img, mask)\n","    return mask\n","    \n","mask = show_images(f\"{data_root}/val\", [3, 5])      # A couple of strange val. images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2J4hcG0nwPX_"},"source":["Пример подсчета метрики:"]},{"cell_type":"code","metadata":{"id":"PVz6cAKRwPYB"},"source":["random_mask = np.random.randint(low=0, high=2, size=mask.shape)\n","get_dice(mask, random_mask), np.sum((mask > 0).astype(int)) / mask.size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FjLGOU4HwPYP"},"source":["// Можно для последовательности масок вычислить среднее значение метрики\n"]},{"cell_type":"markdown","metadata":{"id":"QhAIh3ciwPYm"},"source":["Пример использования функций `encode_rle` и `decode_rle`:\n","1. Функция `encode_rle` используется для кодирования маски в строку для последующей записи в файл;\n","2. Функция `decode_rle` используется для восстановления маски по закодированной строке."]},{"cell_type":"code","metadata":{"id":"tY_q2gCQwPYo"},"source":["rle_mask = encode_rle(mask)\n","rle_mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"we_ei9xEwPZO"},"source":["# Результаты"]},{"cell_type":"markdown","metadata":{"id":"cDy809DHwPZR"},"source":["Пример файла для изображений из `data/valid`:  \n","_Каждую предсказанную маску для изображения из `valid` необходимо закодировать и записать в показанный ниже файл, который служит примером, именно в таком виде нужно будет представить результат Вашего лучшего решения на данных из `valid`._"]},{"cell_type":"code","metadata":{"id":"UaxlHGfmwPZU"},"source":["pred = pd.read_csv(\"data/pred_val_template.csv\")\n","pred.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3q7A3j_wPZn"},"source":["Для данных из `test` требуется создать html страницу + картинки для нее.  \n","Это можно сделать с помощью функции `get_html`, как показано ниже."]},{"cell_type":"code","metadata":{"id":"hB8M3u3DwPZp"},"source":["val_annotations = json.load(open(f\"{data_root}/val/coco_annotations.json\", \"r\"))\n","paths_to_imgs = sorted(glob(f\"{data_root}/val/images/*\"))\n","paths_to_imgs = paths_to_imgs[:10]\n","img_ids = [int(path.split(\"/\")[-1].split(\".\")[0]) for path in paths_to_imgs]\n","masks = [get_mask(img_id, val_annotations) for img_id in sorted(img_ids)]\n","\n","path_to_save = \"results/example\"\n","# generate_images_for_html(paths_to_imgs, masks, path_to_save=path_to_save)     \n","# generate_html(path_to_save, 10)\n","\n","masks[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y3c3Js9KwPZ0"},"source":["В папке `results` создался файл `example.html` и папка `examples` с используемыми картинками."]},{"cell_type":"code","metadata":{"id":"UKIJQNZjwPZ2"},"source":[""],"execution_count":null,"outputs":[]}]}