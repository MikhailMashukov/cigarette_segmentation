 
Резюме: катастрофически не хватило времени (примерно 3 дня по 7 часов) чтобы разобраться со всем, что надо, и хорошо поэкспериментировать. Успел отладить только одну модель, Mask R-CNN из tutorial’a TorchVision и сделать одну аугментацию путём копирования сигарет на ту же картинку. Идея была достаточно перспективная, но почему-то не сработала. На исходной модели получился dice 0.9546. Предобработку не делал (упустил из виду).
 
Код немного модернизировал, прокомментировал. Файлы, которые требует задание, сгенерировал.
 
 
 
Расширенный отчёт
Так как у меня очень мало опыта с задачами сегментации (единственный - как раз недавно пробовал построить маску проволочек на фотографиях, https://opendatascience.slack.com/archives/C047H3N8L/p1601009588071600), в первую очередь надо читать статьи и применять лучшие техники, найденные человечеством. Что-то я уже мельком читал о сегментации, поэтому сейчас начал пробовать использовать свои наработки по проволочкам и брать новую для себя модель, Mask R-CNN.
Если бы было больше времени, я бы почитал ещё статей и скорее всего попробовал Mask R-CNN с другими базами и U-Net из TorchVision. А возможно, можно было бы настроить mmdetection, там ещё больше моделей. Но реально и для проволочек я тогда провозился несколько дней и тут запутался с U-Net, провозился примерно день. Потом заново взял код с Mask R-CNN из torchvision.detection и быстро запустил для него. 
Я знаю, как устроена U-Net и она здесь выглядит подходящей. 
Также слышал, что иногда лучше работают Mask R-CNN, но не разбирался, как они устроены.
 
Код
Код, взятый из torchvision, лежит в lib/detection. Я немного его модернизировал, описание новых методов есть внутри и в lib/detection/README.md.
Для вас я сделал notebook FinalPresentation.ipynb.

Считаю, что экспорт отдельных функций из библиотеки (как это сделано в lib/__init__.py - это красиво, но не практично для небольших библиотек, используемых для экспериментов - в них торчит много "потрохов" и они часто меняются в процессе работы. А такой экспорт создаёт дополнительную работу. Поэтому я не особо поддерживал этот подход.

 
Модель
Основные проблемы, которые должна решить сеть (как я вижу):
1) найти признаки присутствия сигареты (условно, оранжевые пикселы рядом с, возможно, чёрными), примерную зону её расположения,
2) построить очень точную пиксельную маску.
Сейчас я вижу, что и на обучающих и на тестовых данных всегда по одной сигарете.
Это можно использовать. Например, на каком-то слое будет выдаваться матрица силы уверенности в наличии сигареты (её размер будет соответствовать уменьшенному разрешению исходной картинки), можно "врезаться" в свёрточную сеть, найти максимум в этой матрице и по его координатам вычислить bounding box. 
Однако, вряд ли в реальной жизни будет так же и папка real_test это подтверждает.
Я подозреваю, что для современных сетей задача 2) сложнее. 
Из этого вытекает идея добавить картинки, на которых те же самые сигареты "соприкасаются" с другими комбинациями пикселов фона. Её я и реализовал.
Но почему-то результат получился хуже, и по loss в процессе обучения (почти в 2 раза) и по dice (0.9444 против 0.9546).
Попытки доучить её с уменьшающимся learning rate особых результатов не дали. 
Вообще, у меня есть ощущение, что современным сетям для сегментации не хватает чего-то, похожего на алгоритм flood-fill (заливка одноцветных областей сложной формы). Свёртки работают с квадратами 3*3 пиксела и их "производными", но маски объектов - не такие, они могут пересекать такой квадрат по диагонали. Лучше брать имеющиеся пикселы объекта, в которых мы уверены, и достраивать маски исходя из текущих граничных пикселов и прилегающих к ним. Условно, если наиболее мы уверены в центральных пикселах сигареты, потому что они именно того оранжевого цвета, который мы ищем, то далее они могут быть более тёмного цвета (потому что сигарета объёмная), а далее - ещё более тёмного. Переход сразу от ярко-оранжевому к очень тёмному - это странно. Получается что-то вроде того, для чего приспособлены рекуррентные сети. Но т.к. у меня нет огромного количества времени и знаний, у меня не было и надежды изобрести за 3 дня что-то такое кардинально новое и хорошо работающее.
Стоит так же попробовать увеличить размер головы сети (hidden_layer = 256 в get_instance_segmentation_model), раза в 4
Ещё забыл сделать нормализацию картинок. Это “недорого” и должно заметно помочь.
При ограниченных вычислительных ресурсах есть идея уменьшить размер входных картинок. 
Сигареты занимают только небольшую площадь, я сомневаюсь, что имеет смысл натравливать всю полноценную машину распознавания (все эти сотни свёрток) на всю площадь. По сути, сеть должна понять, что фон неравномерен (травинки и т.п.), а объекты - равномерны.
Также возникает идея сосредоточиться на наиболее равномерных картинках.
Да и вообще, наверное, имеет смысл больше тренироваться на наиболее сложных для сети картинках...
 
После реализации первого варианта и 30 эпох обучения я визуализировал результаты. Они показались вполне хорошими. На обучающей выборке почти всегда (на глаз - примерно в 98% случаев) dice выше 95%. Но обычно и не больше 98%. Чаще всего он меньше, когда сигарета находится среди травы. Это подтверждает мою теорию о том, что самое трудное (после "творческой", но уже хорошо решаемой задачи распознавания окурка) - выделение точных краёв. Это не так сложно (для людей и, думаю, для методов компьютерного зрения и свёрточных сетей) при фоне с мелкой текстурой и примерно равномерной сигарете. А вот фон с травинками имеют схожую форму.
На тестовой - аналогично, результаты приятно меня удивили. 
Обучение шло с постоянной learning rate 0.005, эффективность обучения я оценивал на глаз (смотря на столбец loss в логах). Думаю, если поучить дальше с меньшей lr и без аугментации копированием, результаты ещё немного улучшатся. Просто опять же не хватило времени.

 

