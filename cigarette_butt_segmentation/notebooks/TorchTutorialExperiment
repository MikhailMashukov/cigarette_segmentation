{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python (tf_py3)","language":"python","name":"tf_py3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"TorchTutorialExperiment","provenance":[{"file_id":"1U6sVtVVeq5Pd7eCq1YKZnUk_VH00CgB7","timestamp":1601675524738}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"12eTZAm86zk9","executionInfo":{"status":"ok","timestamp":1601717286322,"user_tz":-420,"elapsed":2161,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}},"outputId":"09260436-5fa1-4c8a-86d3-abc9671c224d","colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["!nvidia-smi\n","\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","%cd \"/content/gdrive/My Drive/cigarette_butt_segmentation\"\n","data_root = '/content/data'\n","if not os.path.exists(data_root):\n","    !unzip data/cig_butts.zip -d $data_root\n","    !mv $data_root/cig_butts/* $data_root\n","    !rm -r $data_root/cig_butts \n","\n","if 0:\n","    %cd /content\n","    !git clone https://github.com/pytorch/vision.git\n","    %cd vision\n","    !git checkout v0.3.0\n","\n","    # !cp references/detection/utils.py ../\n","    # !cp references/detection/transforms.py ../\n","    !cp vision/references/detection/coco_eval.py lib/torchvision\n","    !cp vision/references/detection/engine.py lib/torchvision\n","    # !cp references/detection/coco_utils.py ../\n","\n","    %cd \"/content/gdrive/My Drive/cigarette_butt_segmentation\""],"execution_count":14,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/cigarette_butt_segmentation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bUnpMSimwPW6","executionInfo":{"status":"ok","timestamp":1601717286326,"user_tz":-420,"elapsed":2084,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}},"outputId":"5527a259-d837-4396-bab6-02056f1d0884","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import cv2\n","import json\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from PIL import ImageFile\n","from glob import glob\n","\n","from lib import *\n","from lib.net import *\n","from lib.torchvision.transforms import get_transform\n","from lib.torchvision import train\n","from lib.torchvision.utils import *\n","\n","%matplotlib inline\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":15,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KA27AA9IU9u0","executionInfo":{"status":"ok","timestamp":1601717307385,"user_tz":-420,"elapsed":23097,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["# import torchvision.models.segmentation as segmentation\n","\n","# model = segmentation.deeplabv3_resnet50(True, True, 1)\n","\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n"," \n","# load a model pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n"," \n","# replace the classifier with a new one, that has\n","# num_classes which is user-defined\n","num_classes = 2  # 1 class (person) + background\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"fyqUrAwiY2Md","executionInfo":{"status":"ok","timestamp":1601717530166,"user_tz":-420,"elapsed":1728,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}},"outputId":"11863fd3-dce7-41d8-a38f-76e54de8543d","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["dataset = CigDataset(data_root + '/train', get_transform(train=True))\n","dataset_test = CigDataset(data_root + '/val', get_transform(train=False))\n","\n","# split the dataset in train and test set\n","torch.manual_seed(1)\n","# indices = torch.randperm(len(dataset)).tolist()\n","# dataset = torch.utils.data.Subset(dataset, indices[:-50])\n","# dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n","\n","# define training and validation data loaders\n","data_loader = torch.utils.data.DataLoader(\n","    dataset, batch_size=2, shuffle=True, num_workers=4,\n","    collate_fn=collate_fn)\n","\n","data_loader_test = torch.utils.data.DataLoader(\n","    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n","    collate_fn=collate_fn)\n","\n","# dataset[0]"],"execution_count":19,"outputs":[{"output_type":"stream","text":["2000 images\n","200 images\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oL1OEv2layHM","executionInfo":{"status":"ok","timestamp":1601717842373,"user_tz":-420,"elapsed":2460,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","num_classes = 2\n","model = get_instance_segmentation_model(num_classes)\n","model.to(device)\n","# criterion = train.get_criterion()\n","\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                               step_size=10,\n","                                               gamma=0.1)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3NIzEjXbZE0","executionInfo":{"status":"error","timestamp":1601717842769,"user_tz":-420,"elapsed":2783,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}},"outputId":"ce25de5f-d814-4256-be1d-dab1ed33c9cb","colab":{"base_uri":"https://localhost:8080/","height":441}},"source":["num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    # train.train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n","    train.train_one_epoch(model, train.criterion, optimizer, data_loader, lr_scheduler, device,\n","                          epoch, print_freq=10)\n","    # lr_scheduler.step()\n","    evaluate(model, data_loader_test, device=device)"],"execution_count":23,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-603f74473c81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# train.train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     train.train_one_epoch(model, train.criterion, optimizer, data_loader, lr_scheduler, device,\n\u001b[0;32m----> 6\u001b[0;31m                           epoch, print_freq=10)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# lr_scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/cigarette_butt_segmentation/lib/torchvision/train.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, optimizer, data_loader, lr_scheduler, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In training mode, targets should be passed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: In training mode, targets should be passed"]}]},{"cell_type":"markdown","metadata":{"id":"rytHcSeMwPXi"},"source":["# Данные, метрики и доступные функции"]},{"cell_type":"markdown","metadata":{"id":"uCeB_dCswPXl"},"source":["Посмотрим на данные:"]},{"cell_type":"code","metadata":{"id":"ZEvZJdDVwPXo","executionInfo":{"status":"aborted","timestamp":1601717842745,"user_tz":-420,"elapsed":2697,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["def show_images(data_path, img_ids):\n","    images = os.listdir(f\"{data_path}/images\")\n","    annotations = json.load(open(f\"{data_path}/coco_annotations.json\", \"r\"))\n","    for img_id in img_ids:\n","        img = None\n","        for ext in ['png', 'jpg', 'jpeg', 'gif']:\n","            img_path = f\"{data_path}/images/{img_id:08}.{ext}\"\n","            if os.path.exists(img_path):\n","                img = np.array(Image.open(img_path))\n","        mask = utils.get_mask(img_id, annotations)  # [130:170, 270:350]\n","        show.show_img_with_mask(img, mask)\n","    return mask\n","    \n","mask = show_images(f\"{data_root}/val\", [3, 5])      # A couple of strange val. images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2J4hcG0nwPX_"},"source":["Пример подсчета метрики:"]},{"cell_type":"code","metadata":{"id":"PVz6cAKRwPYB","executionInfo":{"status":"aborted","timestamp":1601717842748,"user_tz":-420,"elapsed":2664,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["random_mask = np.random.randint(low=0, high=2, size=mask.shape)\n","get_dice(mask, random_mask), np.sum((mask > 0).astype(int)) / mask.size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FjLGOU4HwPYP"},"source":["// Можно для последовательности масок вычислить среднее значение метрики\n"]},{"cell_type":"markdown","metadata":{"id":"QhAIh3ciwPYm"},"source":["Пример использования функций `encode_rle` и `decode_rle`:\n","1. Функция `encode_rle` используется для кодирования маски в строку для последующей записи в файл;\n","2. Функция `decode_rle` используется для восстановления маски по закодированной строке."]},{"cell_type":"code","metadata":{"id":"tY_q2gCQwPYo","executionInfo":{"status":"aborted","timestamp":1601717842750,"user_tz":-420,"elapsed":2628,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["rle_mask = encode_rle(mask)\n","rle_mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"we_ei9xEwPZO"},"source":["# Результаты"]},{"cell_type":"markdown","metadata":{"id":"cDy809DHwPZR"},"source":["Пример файла для изображений из `data/valid`:  \n","_Каждую предсказанную маску для изображения из `valid` необходимо закодировать и записать в показанный ниже файл, который служит примером, именно в таком виде нужно будет представить результат Вашего лучшего решения на данных из `valid`._"]},{"cell_type":"code","metadata":{"id":"UaxlHGfmwPZU","executionInfo":{"status":"aborted","timestamp":1601717842755,"user_tz":-420,"elapsed":2587,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["pred = pd.read_csv(\"data/pred_val_template.csv\")\n","pred.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3q7A3j_wPZn"},"source":["Для данных из `test` требуется создать html страницу + картинки для нее.  \n","Это можно сделать с помощью функции `get_html`, как показано ниже."]},{"cell_type":"code","metadata":{"id":"hB8M3u3DwPZp","executionInfo":{"status":"aborted","timestamp":1601717842759,"user_tz":-420,"elapsed":2538,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["val_annotations = json.load(open(f\"{data_root}/val/coco_annotations.json\", \"r\"))\n","paths_to_imgs = sorted(glob(f\"{data_root}/val/images/*\"))\n","paths_to_imgs = paths_to_imgs[:10]\n","img_ids = [int(path.split(\"/\")[-1].split(\".\")[0]) for path in paths_to_imgs]\n","masks = [get_mask(img_id, val_annotations) for img_id in sorted(img_ids)]\n","\n","path_to_save = \"results/example\"\n","# generate_images_for_html(paths_to_imgs, masks, path_to_save=path_to_save)     \n","# generate_html(path_to_save, 10)\n","\n","masks[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y3c3Js9KwPZ0"},"source":["В папке `results` создался файл `example.html` и папка `examples` с используемыми картинками."]},{"cell_type":"code","metadata":{"id":"UKIJQNZjwPZ2","executionInfo":{"status":"aborted","timestamp":1601717842763,"user_tz":-420,"elapsed":2451,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":[""],"execution_count":null,"outputs":[]}]}